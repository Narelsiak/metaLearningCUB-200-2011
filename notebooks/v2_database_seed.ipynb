{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import psycopg2.extensions\n",
    "import numpy as np\n",
    "\n",
    "def adapt_numpy_int64(numpy_int64):\n",
    "    return psycopg2.extensions.AsIs(int(numpy_int64))\n",
    "\n",
    "psycopg2.extensions.register_adapter(np.int64, adapt_numpy_int64)\n",
    "\n",
    "class DatabaseController:\n",
    "    def __init__(self, dbname=\"meta_learning\", user=\"user\", password=\"1234\", host=\"localhost\", port=\"5432\"):\n",
    "        self.db_params = {\n",
    "            \"dbname\": dbname,\n",
    "            \"user\": user,\n",
    "            \"password\": password,\n",
    "            \"host\": host,\n",
    "            \"port\": port\n",
    "        }\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def _get_connection(self):\n",
    "        if not self.conn:\n",
    "            self.conn = psycopg2.connect(**self.db_params)\n",
    "            self.cursor = self.conn.cursor()\n",
    "        return self.conn, self.cursor\n",
    "    \n",
    "    def close_connection(self):\n",
    "        if self.conn:\n",
    "            self.conn.commit()\n",
    "            self.cursor.close()\n",
    "            self.conn.close()\n",
    "            self.conn = None\n",
    "            self.cursor = None\n",
    "\n",
    "    def execute_query(self, query, params=None, fetch=False):\n",
    "        conn, cursor = self._get_connection()\n",
    "        try:\n",
    "            cursor.execute(query, params)\n",
    "            if fetch:\n",
    "                return cursor.fetchall()\n",
    "            conn.commit()\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            print(\"Error:\", e)\n",
    "            raise e\n",
    "\n",
    "    def create_table(self, table_name, columns):\n",
    "        columns_str = \", \".join([f\"{col} {dtype}\" for col, dtype in columns.items()])\n",
    "        query = sql.SQL(f\"CREATE TABLE IF NOT EXISTS {table_name} ({columns_str});\")\n",
    "        self.execute_query(query)\n",
    "\n",
    "    def insert_data(self, table_name, data):\n",
    "        values_placeholders = \", \".join([\"%s\"] * len(data))\n",
    "        query = sql.SQL(f\"INSERT INTO {table_name} VALUES ({values_placeholders});\")\n",
    "        self.execute_query(query, tuple(data.values()))\n",
    "\n",
    "    def fetch_data(self, table_name, conditions=None):\n",
    "        base_query = sql.SQL(\"SELECT * FROM {}\").format(sql.Identifier(table_name))\n",
    "        \n",
    "        if conditions:\n",
    "            where_clause = sql.SQL(\" WHERE \") + sql.SQL(\" AND \").join(\n",
    "                sql.Composed([sql.Identifier(col), sql.SQL(\"= %s\")]) for col in conditions.keys()\n",
    "            )\n",
    "            query = base_query + where_clause\n",
    "            return self.execute_query(query, tuple(conditions.values()), fetch=True)\n",
    "        \n",
    "        return self.execute_query(base_query, fetch=True)\n",
    "\n",
    "    def clear_table(self, table_name):\n",
    "        query = sql.SQL(f\"DELETE FROM {table_name};\")\n",
    "        self.execute_query(query)\n",
    "\n",
    "    def get_all_data(self, table_name):\n",
    "        query = sql.SQL(f\"SELECT * FROM {table_name};\")\n",
    "        return self.execute_query(query, fetch=True)\n",
    "\n",
    "    def get_data_length(self, table_name):\n",
    "        query = sql.SQL(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "        result = self.execute_query(query, fetch=True)\n",
    "        return result[0][0] if result else 0\n",
    "    \n",
    "    def table_exists(self, table_name):\n",
    "        query = sql.SQL(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = %s);\")\n",
    "        result = self.execute_query(query, (table_name,), fetch=True)\n",
    "        return result[0][0] if result else False\n",
    "    \n",
    "    def get_columns(self, table_name):\n",
    "        query = sql.SQL(\"SELECT column_name FROM information_schema.columns WHERE table_name = %s;\")\n",
    "        result = self.execute_query(query, (table_name,), fetch=True)\n",
    "        return [row[0] for row in result] if result else []\n",
    "    \n",
    "    def delete_by_condition(self, table_name, conditions):    \n",
    "        where_clause = \" AND \".join([f\"{col} = %s\" for col in conditions.keys()])\n",
    "        query = sql.SQL(f\"DELETE FROM {table_name} WHERE {where_clause};\")\n",
    "        self.execute_query(query, tuple(conditions.values()))\n",
    "\n",
    "    def update_data(self, table_name, updates, conditions):\n",
    "        set_clause = \", \".join([f\"{col} = %s\" for col in updates.keys()])\n",
    "        where_clause = \" AND \".join([f\"{col} = %s\" for col in conditions.keys()])\n",
    "        query = sql.SQL(f\"UPDATE {table_name} SET {set_clause} WHERE {where_clause};\")\n",
    "        self.execute_query(query, tuple(updates.values()) + tuple(conditions.values()))\n",
    "    \n",
    "    def get_tables(self):\n",
    "        query = sql.SQL(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\")\n",
    "        result = self.execute_query(query, fetch=True)\n",
    "        return [row[0] for row in result] if result else []\n",
    "\n",
    "    def drop_all_tables(self):\n",
    "        query = \"\"\"\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'public'\n",
    "        AND table_type = 'BASE TABLE';\n",
    "        \"\"\"\n",
    "        tables = self.execute_query(query, fetch=True)\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            query = sql.SQL(f\"DROP TABLE IF EXISTS {table_name} CASCADE;\")\n",
    "            self.execute_query(query)\n",
    "\n",
    "        print(\"All tables have been dropped.\")\n",
    "\n",
    "\n",
    "    def execute_raw_query(self, query, params=None):\n",
    "        return self.execute_query(query, params, fetch=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables have been dropped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['images', 'image_class_labels', 'classes', 'train_test_split']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DatabaseController()\n",
    "db.drop_all_tables()\n",
    "\n",
    "db.create_table(\"images\", {\n",
    "    \"id\": \"INTEGER PRIMARY KEY\",\n",
    "    \"image_name\": \"TEXT NOT NULL UNIQUE\"\n",
    "})\n",
    "\n",
    "db.create_table(\"classes\", {\n",
    "    \"id\": \"INTEGER PRIMARY KEY\",\n",
    "    \"class_name\": \"TEXT NOT NULL UNIQUE\"\n",
    "})\n",
    "\n",
    "db.create_table(\"image_class_labels\", {\n",
    "    \"image_id\": \"INTEGER NOT NULL\",\n",
    "    \"class_id\": \"INTEGER NOT NULL\",    \n",
    "    \"PRIMARY KEY (image_id)\": \"\",\n",
    "    \"FOREIGN KEY (image_id)\": \"REFERENCES images(id) ON DELETE CASCADE\",\n",
    "    \"FOREIGN KEY (class_id)\": \"REFERENCES classes(id) ON DELETE CASCADE\"\n",
    "    })\n",
    "\n",
    "db.create_table(\"train_test_split\", {\n",
    "    \"image_id\": \"INTEGER NOT NULL PRIMARY KEY\",\n",
    "    \"is_training_image\": \"INTEGER NOT NULL CHECK(is_training_image IN (0, 1))\",\n",
    "    \"FOREIGN KEY (image_id)\": \"REFERENCES images(id) ON DELETE CASCADE\"\n",
    "    })\n",
    "\n",
    "# db.create_table(\"bounding_boxes\", {\n",
    "#     \"image_id\": \"INTEGER NOT NULL PRIMARY KEY\",\n",
    "#     \"x\": \"REAL NOT NULL\",\n",
    "#     \"y\": \"REAL NOT NULL\",\n",
    "#     \"width\": \"REAL NOT NULL\",\n",
    "#     \"height\": \"REAL NOT NULL\",\n",
    "#     \"FOREIGN KEY (image_id)\": \"REFERENCES images(id) ON DELETE CASCADE\"\n",
    "#     })\n",
    "\n",
    "# db.create_table(\"parts\", {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"part_name\": \"TEXT NOT NULL UNIQUE\"\n",
    "# })\n",
    "\n",
    "# db.create_table(\"part_locs\", {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"image_id\": \"INTEGER NOT NULL\",\n",
    "#     \"part_id\": \"INTEGER NOT NULL\",\n",
    "#     \"x\": \"REAL NOT NULL\",\n",
    "#     \"y\": \"REAL NOT NULL\",\n",
    "#     \"visible\": \"INTEGER NOT NULL CHECK(visible IN (0, 1))\",\n",
    "#     \"FOREIGN KEY (image_id)\": \"REFERENCES images(id) ON DELETE CASCADE\",\n",
    "#     \"FOREIGN KEY (part_id)\": \"REFERENCES parts(id) ON DELETE CASCADE\",\n",
    "#     \"UNIQUE (image_id, part_id)\": \"\"\n",
    "#     })\n",
    "\n",
    "# db.create_table(\"attributes\", {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"attribute_name\": \"TEXT NOT NULL UNIQUE\"\n",
    "# })\n",
    "\n",
    "# db.create_table(\"certainties\", {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"certainty_name\": \"TEXT NOT NULL UNIQUE\"\n",
    "# })\n",
    "\n",
    "# db.create_table(\"image_attribute_labels\", {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"image_id\": \"INTEGER NOT NULL\",\n",
    "#     \"attribute_id\": \"INTEGER NOT NULL\",\n",
    "#     \"is_present\": \"INTEGER NOT NULL CHECK(is_present IN (0, 1))\",\n",
    "#     \"certainty_id\": \"INTEGER NOT NULL\",\n",
    "#     \"time\": \"REAL NOT NULL\",\n",
    "#     \"FOREIGN KEY (image_id)\": \"REFERENCES images(id) ON DELETE CASCADE\",\n",
    "#     \"FOREIGN KEY (attribute_id)\": \"REFERENCES attributes(id) ON DELETE CASCADE\",\n",
    "#     \"FOREIGN KEY (certainty_id)\": \"REFERENCES certainties(id) ON DELETE CASCADE\"\n",
    "# })\n",
    "\n",
    "# db.create_table(\"class_attribute_labels_continuous\", {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"class_id\": \"INTEGER NOT NULL\",\n",
    "#     \"attribute_id\": \"INTEGER NOT NULL\",\n",
    "#     \"value\": \"REAL NOT NULL\",\n",
    "#     \"FOREIGN KEY (class_id)\": \"REFERENCES classes(id) ON DELETE CASCADE\",\n",
    "#     \"FOREIGN KEY (attribute_id)\": \"REFERENCES attributes(id) ON DELETE CASCADE\",\n",
    "#     \"UNIQUE (class_id, attribute_id)\": \"\"\n",
    "# })\n",
    "\n",
    "# table_definition = {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"class_id\": \"INTEGER NOT NULL\"\n",
    "# }\n",
    "\n",
    "# # Dodaj 312 atrybutów\n",
    "# for i in range(1, 313):\n",
    "#     table_definition[f\"attribute_{i}\"] = f\"REAL NOT NULL CHECK(attribute_{i} >= 0 AND attribute_{i} <= 100)\"\n",
    "\n",
    "# # Dodaj ograniczenia\n",
    "# table_definition[\"FOREIGN KEY (class_id)\"] = \"REFERENCES classes(id) ON DELETE CASCADE\"\n",
    "# table_definition[\"CONSTRAINT uq_class_attr UNIQUE (class_id)\"] = \"\"\n",
    "\n",
    "# db.create_table(\"class_attribute_labels_continuous\", table_definition)\n",
    "\n",
    "# db.create_table(\"part_click_locs\", {\n",
    "#     \"id\": \"INTEGER PRIMARY KEY\",\n",
    "#     \"image_id\": \"INTEGER NOT NULL\",\n",
    "#     \"part_id\": \"INTEGER NOT NULL\",\n",
    "#     \"x\": \"REAL NOT NULL\",\n",
    "#     \"y\": \"REAL NOT NULL\",\n",
    "#     \"visible\": \"INTEGER NOT NULL CHECK(visible IN (0, 1))\",\n",
    "#     \"time\": \"REAL NOT NULL\",\n",
    "#     \"FOREIGN KEY (image_id)\": \"REFERENCES images(id) ON DELETE CASCADE\",\n",
    "#     \"FOREIGN KEY (part_id)\": \"REFERENCES parts(id) ON DELETE CASCADE\"\n",
    "# })\n",
    "db.get_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     int64\n",
      "1    object\n",
      "dtype: object\n",
      "0                                                    1\n",
      "1    001.Black_footed_Albatross/Black_Footed_Albatr...\n",
      "Name: 0, dtype: object\n",
      "0     int64\n",
      "1    object\n",
      "dtype: object\n",
      "0                             1\n",
      "1    001.Black_footed_Albatross\n",
      "Name: 0, dtype: object\n",
      "0    int64\n",
      "1    int64\n",
      "dtype: object\n",
      "0    1\n",
      "1    1\n",
      "Name: 0, dtype: int64\n",
      "0    int64\n",
      "1    int64\n",
      "dtype: object\n",
      "0    1\n",
      "1    0\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data/raw/CUB_200_2011')\n",
    "\n",
    "def load_data_from_txt(file_name, delimiter=' ', dtype=None):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    df = pd.read_csv(file_path, sep=delimiter, header=None, dtype=dtype)\n",
    "    return df\n",
    "\n",
    "def load_data_from_txt_with_id(file_name, delimiter=' ', dtype=None):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    df = pd.read_csv(file_path, sep=delimiter, header=None, dtype=dtype)\n",
    "    df.insert(0, 'id', range(1, len(df) + 1))\n",
    "\n",
    "    df.columns = [str(i) for i in range(len(df.columns))]\n",
    "\n",
    "    return df\n",
    "\n",
    "def insert_data_from_dataframe(data, table_name):\n",
    "    for index, row in data.iterrows():\n",
    "        data = {f\"col{i}\": row[i] for i in range(len(row))}\n",
    "        db.insert_data(table_name, data)\n",
    "\n",
    "images_file = os.path.join(data_dir, 'images.txt')\n",
    "classes_file = os.path.join(data_dir, 'classes.txt')\n",
    "image_class_labels_file = os.path.join(data_dir, 'image_class_labels.txt')\n",
    "train_test_split_file = os.path.join(data_dir, 'train_test_split.txt')\n",
    "# bounding_boxes_file = os.path.join(data_dir, 'bounding_boxes.txt')\n",
    "# parts_file = os.path.join(data_dir, 'parts/parts.txt')\n",
    "# part_locs_file = os.path.join(data_dir, 'parts/part_locs.txt')\n",
    "# part_click_locs_file = os.path.join(data_dir, 'parts/part_click_locs.txt')\n",
    "# attributes_file = os.path.join(data_dir, 'attributes/attributes.txt')\n",
    "# certainties_file = os.path.join(data_dir, 'attributes/certainties.txt')\n",
    "# image_attribute_labels_file = os.path.join(data_dir, 'attributes/image_attribute_labels.txt')\n",
    "# class_attribute_labels_continuous_file = os.path.join(data_dir, 'attributes/class_attribute_labels_continuous.txt')\n",
    "\n",
    "image_data = load_data_from_txt(images_file, delimiter=' ', dtype={0: int, 1: str})\n",
    "classes_data = load_data_from_txt(classes_file, delimiter=' ', dtype={0: int, 1: str})\n",
    "image_class_labels_data = load_data_from_txt(image_class_labels_file, delimiter=' ', dtype={0: int, 1: int})\n",
    "train_test_split_data = load_data_from_txt(train_test_split_file, delimiter=' ', dtype={0: int, 1: int})\n",
    "# bounding_boxes_data = load_data_from_txt(bounding_boxes_file, delimiter=' ', dtype={0: int, 1: int, 2: int, 3: int, 4: int})\n",
    "# parts_data = load_data_from_txt(parts_file, delimiter=' ', dtype={0: int, 1: str})\n",
    "# part_locs_data = load_data_from_txt_with_id(part_locs_file, delimiter=' ', dtype={0: int, 1: int, 2: int, 3: int, 4: int, 5: int})\n",
    "# part_click_locs_data = load_data_from_txt_with_id(part_click_locs_file, delimiter=' ',  dtype={0: int, 1: int, 2: int, 3: int, 4: int, 5: float})\n",
    "# attributes_data = load_data_from_txt(attributes_file, delimiter=' ', dtype={0: int, 1: str})\n",
    "# certainties_data = load_data_from_txt(certainties_file, delimiter=' ', dtype={0: int, 1: str})\n",
    "# image_attribute_labels_data = load_data_from_txt_with_id(image_attribute_labels_file, delimiter=' ', dtype={0: int, 1: int, 2: int, 3: int, 4: float})\n",
    "# class_attribute_labels_continuous_data = load_data_from_txt(class_attribute_labels_continuous_file, delimiter=' ')\n",
    "\n",
    "insert_data_from_dataframe(image_data, \"images\")\n",
    "insert_data_from_dataframe(classes_data, \"classes\")\n",
    "insert_data_from_dataframe(image_class_labels_data, \"image_class_labels\")\n",
    "insert_data_from_dataframe(train_test_split_data, \"train_test_split\")\n",
    "# insert_data_from_dataframe(bounding_boxes_data, \"bounding_boxes\")\n",
    "# insert_data_from_dataframe(parts_data, \"parts\")\n",
    "# insert_data_from_dataframe(part_locs_data, \"part_locs\")\n",
    "# insert_data_from_dataframe(part_click_locs_data, \"part_click_locs\")\n",
    "# insert_data_from_dataframe(attributes_data, \"attributes\")\n",
    "# insert_data_from_dataframe(certainties_data, \"certainties\")\n",
    "# insert_data_from_dataframe(image_attribute_labels_data, \"image_attribute_labels\")\n",
    "#insert_data_from_dataframe(class_attribute_labels_continuous_data, \"class_attribute_labels_continuous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                         image_name  image_id  class_id  \\\n",
      "0   1  001.Black_footed_Albatross/Black_Footed_Albatr...         1         1   \n",
      "1   2  001.Black_footed_Albatross/Black_Footed_Albatr...         2         1   \n",
      "2   3  001.Black_footed_Albatross/Black_Footed_Albatr...         3         1   \n",
      "3   4  001.Black_footed_Albatross/Black_Footed_Albatr...         4         1   \n",
      "4   5  001.Black_footed_Albatross/Black_Footed_Albatr...         5         1   \n",
      "\n",
      "                   class_name  is_training_image  \n",
      "0  001.Black_footed_Albatross                  0  \n",
      "1  001.Black_footed_Albatross                  1  \n",
      "2  001.Black_footed_Albatross                  0  \n",
      "3  001.Black_footed_Albatross                  1  \n",
      "4  001.Black_footed_Albatross                  1  \n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        self.db = DatabaseController()\n",
    "    def fetch_table_as_df(self, table_name):\n",
    "        data = self.db.get_all_data(table_name)\n",
    "        columns = self.db.get_columns(table_name)\n",
    "        return pd.DataFrame(data, columns=columns) if data else pd.DataFrame(columns=columns)\n",
    "    def load_and_merge_data(self):\n",
    "        df_images = self.fetch_table_as_df(\"images\")\n",
    "        df_classes = self.fetch_table_as_df(\"classes\")\n",
    "        df_labels = self.fetch_table_as_df(\"image_class_labels\")\n",
    "        df_split = self.fetch_table_as_df(\"train_test_split\")\n",
    "\n",
    "        if df_images.empty or df_classes.empty or df_labels.empty or df_split.empty:\n",
    "            print(\"⚠️ Data missing from one of the tables!\")\n",
    "            return None\n",
    "        \n",
    "        df = df_images.merge(df_labels, left_on=\"id\", right_on=\"image_id\")\n",
    "        df = df.merge(df_classes, left_on=\"class_id\", right_on=\"id\", suffixes=(\"\", \"_class\"))\n",
    "        df = df.merge(df_split, on=\"image_id\")\n",
    "\n",
    "        df.drop(columns=[\"id_class\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "        return df\n",
    "\n",
    "data_loader = DataLoader()\n",
    "df_combined = data_loader.load_and_merge_data()\n",
    "\n",
    "print(df_combined.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
