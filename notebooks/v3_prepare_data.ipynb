{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>is_training_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         image_name  image_id  class_id  \\\n",
       "0   1  001.Black_footed_Albatross/Black_Footed_Albatr...         1         1   \n",
       "1   2  001.Black_footed_Albatross/Black_Footed_Albatr...         2         1   \n",
       "2   3  001.Black_footed_Albatross/Black_Footed_Albatr...         3         1   \n",
       "3   4  001.Black_footed_Albatross/Black_Footed_Albatr...         4         1   \n",
       "4   5  001.Black_footed_Albatross/Black_Footed_Albatr...         5         1   \n",
       "\n",
       "                   class_name  is_training_image  \n",
       "0  001.Black_footed_Albatross                  0  \n",
       "1  001.Black_footed_Albatross                  1  \n",
       "2  001.Black_footed_Albatross                  0  \n",
       "3  001.Black_footed_Albatross                  1  \n",
       "4  001.Black_footed_Albatross                  1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from meta_project.data.data_loader import DataLoader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "df = data_loader.load_and_merge_data()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3090 Ti\n",
      "Loading dataset using ImageFolder...\n",
      "Found 11788 images in 200 classes.\n",
      "Splitting into Train (8841) and Test (2947) sets...\n",
      "Dataset split complete.\n",
      "Creating DataLoaders with Batch Size: 8, Num Workers: 2\n",
      "DataLoaders created.\n",
      "Loading ResNet18 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Michal/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 37.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified final layer for 200 classes.\n",
      "Model moved to device.\n",
      "Loss function and optimizer defined.\n",
      "\n",
      "--- Starting Training for 10 Epochs ---\n",
      "Initial RAM Usage: 41.6% Used\n",
      "Initial GPU Memory: 43.08 MB Allocated, 66.00 MB Reserved\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import time\n",
    "import psutil # Do monitorowania pamięci\n",
    "import gc     # Garbage collector\n",
    "\n",
    "# --- Konfiguracja ---\n",
    "ROOT_DIR = os.path.join(os.getcwd(), \"data\", \"raw\", \"CUB_200_2011\", \"images\")\n",
    "# !!! KLUCZOWY PARAMETR - ZACZNIJ OD MAŁEJ WARTOŚCI !!!\n",
    "BATCH_SIZE = 8  # Spróbuj 8, jeśli nadal za dużo, zmniejsz do 4, 2 lub 1\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 10 # Zwiększ dla lepszych wyników, ale najpierw ustabilizuj pamięć\n",
    "TEST_SPLIT_RATIO = 0.25\n",
    "NUM_WORKERS = 2 # Liczba procesów do ładowania danych. Zacznij od 0 lub 2.\n",
    "                # Zwiększaj ostrożnie, bo też zużywają RAM. 0 = ładowanie w głównym procesie.\n",
    "\n",
    "# Sprawdź, czy ścieżka istnieje\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    raise FileNotFoundError(f\"Dataset directory not found: {ROOT_DIR}. \"\n",
    "                         \"Please ensure the CUB_200_2011 dataset is downloaded and extracted correctly.\")\n",
    "\n",
    "# --- Przygotowanie urządzenia (GPU lub CPU) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# --- Transformacje Danych ---\n",
    "# Użyjemy tych samych transformacji co poprzednio\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Transformacje dla zbioru treningowego (z augmentacją)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Transformacje dla zbioru walidacyjnego/testowego (bez augmentacji)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# --- Ładowanie Danych ---\n",
    "print(\"Loading dataset using ImageFolder...\")\n",
    "# ImageFolder oczekuje struktury: root/class/image.jpg\n",
    "# Automatycznie znajdzie klasy i przypisze indeksy\n",
    "full_dataset = datasets.ImageFolder(root=ROOT_DIR)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "if num_classes == 0:\n",
    "    raise ValueError(f\"No classes found in {ROOT_DIR}. Check dataset structure.\")\n",
    "if num_classes != 200:\n",
    "     print(f\"Warning: Expected 200 classes, but found {num_classes}. Check dataset structure.\")\n",
    "\n",
    "print(f\"Found {len(full_dataset)} images in {num_classes} classes.\")\n",
    "\n",
    "# --- Podział na Zbiór Treningowy i Testowy ---\n",
    "total_size = len(full_dataset)\n",
    "test_size = int(TEST_SPLIT_RATIO * total_size)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "print(f\"Splitting into Train ({train_size}) and Test ({test_size}) sets...\")\n",
    "# Ustawiamy generator dla powtarzalności podziału\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "# Domyślnie ImageFolder nie ma atrybutu 'targets', musimy go dodać lub użyć innej metody podziału\n",
    "# Prostsza metoda: załaduj z różnymi transformacjami\n",
    "train_dataset = datasets.ImageFolder(root=ROOT_DIR, transform=transform_train)\n",
    "test_dataset_with_test_transform = datasets.ImageFolder(root=ROOT_DIR, transform=transform_test)\n",
    "\n",
    "# Teraz dzielimy indeksy, a nie same datasety\n",
    "indices = list(range(total_size))\n",
    "train_indices, test_indices = random_split(indices, [train_size, test_size], generator=generator)\n",
    "\n",
    "# Tworzymy Subsets z odpowiednimi transformacjami\n",
    "from torch.utils.data import Subset\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "test_subset = Subset(test_dataset_with_test_transform, test_indices)\n",
    "\n",
    "print(\"Dataset split complete.\")\n",
    "\n",
    "# --- Tworzenie DataLoaderów ---\n",
    "# DataLoader będzie ładował dane w batchach\n",
    "# pin_memory=True może przyspieszyć transfer na GPU (jeśli używasz CUDA)\n",
    "# Ustaw `persistent_workers=True` jeśli `NUM_WORKERS > 0` dla potencjalnej poprawy szybkości między epokami\n",
    "use_persistent_workers = NUM_WORKERS > 0\n",
    "\n",
    "print(f\"Creating DataLoaders with Batch Size: {BATCH_SIZE}, Num Workers: {NUM_WORKERS}\")\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=use_persistent_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_subset,\n",
    "    batch_size=BATCH_SIZE, # Można użyć większego batcha do testów, jeśli RAM pozwala\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=use_persistent_workers\n",
    ")\n",
    "print(\"DataLoaders created.\")\n",
    "\n",
    "# --- Definicja Modelu ---\n",
    "print(\"Loading ResNet18 model...\")\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Zamrożenie wag (opcjonalnie, na początku transfer learningu)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Modyfikacja ostatniej warstwy (klasyfikatora)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "print(f\"Modified final layer for {num_classes} classes.\")\n",
    "\n",
    "# Przeniesienie modelu na odpowiednie urządzenie\n",
    "model.to(device)\n",
    "print(\"Model moved to device.\")\n",
    "\n",
    "# --- Definicja Funkcji Straty i Optymalizatora ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optymalizujemy tylko parametry, które wymagają gradientu (na wypadek zamrożenia)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "print(\"Loss function and optimizer defined.\")\n",
    "\n",
    "# --- Pętla Treningowa ---\n",
    "print(f\"\\n--- Starting Training for {EPOCHS} Epochs ---\")\n",
    "print(f\"Initial RAM Usage: {psutil.virtual_memory().percent}% Used\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "     print(f\"Initial GPU Memory: {torch.cuda.memory_allocated(device)/1024**2:.2f} MB Allocated, {torch.cuda.memory_reserved(device)/1024**2:.2f} MB Reserved\")\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time_epoch = time.time()\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    # --- Faza Treningu ---\n",
    "    model.train() # Ustawienie modelu w tryb treningu\n",
    "    running_loss = 0.0\n",
    "    batches_processed_train = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        start_time_batch = time.time()\n",
    "        # Przeniesienie danych na urządzenie\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Wyzerowanie gradientów\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Przejście w przód (forward pass)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Przejście wstecz (backward pass) i optymalizacja\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statystyki\n",
    "        running_loss += loss.item()\n",
    "        batches_processed_train += 1\n",
    "\n",
    "        if (i + 1) % 20 == 0: # Loguj co 20 batchy\n",
    "            avg_loss_recent = running_loss / batches_processed_train # Średnia od początku epoki\n",
    "            batch_time = time.time() - start_time_batch\n",
    "            print(f'  Batch [{i+1:>4}/{len(train_loader):>4}] Loss: {avg_loss_recent:.4f} | Time/Batch: {batch_time:.3f}s')\n",
    "            # Reset running loss for recent average if needed, or keep accumulating epoch loss\n",
    "            # running_loss = 0.0 # If you want loss for only last 20 batches\n",
    "            # batches_processed_train = 0\n",
    "\n",
    "        # Agresywne czyszczenie pamięci (użyj jeśli masz problemy)\n",
    "        del inputs, labels, outputs, loss\n",
    "        if device == torch.device(\"cuda\"):\n",
    "             torch.cuda.empty_cache()\n",
    "        # gc.collect() # gc.collect() może być wolne, używaj oszczędnie\n",
    "\n",
    "    epoch_loss_train = running_loss / len(train_loader)\n",
    "\n",
    "    # --- Faza Walidacji ---\n",
    "    model.eval() # Ustawienie modelu w tryb ewaluacji\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad(): # Wyłączenie obliczania gradientów\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Opcjonalne czyszczenie\n",
    "            del inputs, labels, outputs, loss, predicted\n",
    "            if device == torch.device(\"cuda\"):\n",
    "                 torch.cuda.empty_cache()\n",
    "            # gc.collect()\n",
    "\n",
    "    epoch_loss_val = val_loss / len(test_loader)\n",
    "    epoch_acc_val = 100 * correct / total if total > 0 else 0\n",
    "    end_time_epoch = time.time()\n",
    "    epoch_duration = end_time_epoch - start_time_epoch\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Epoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train Loss: {epoch_loss_train:.4f}\")\n",
    "    print(f\"  Val Loss:   {epoch_loss_val:.4f}\")\n",
    "    print(f\"  Val Acc:    {epoch_acc_val:.2f}%\")\n",
    "    print(f\"  Duration:   {epoch_duration:.2f}s\")\n",
    "    print(f\"  RAM Usage: {psutil.virtual_memory().percent}% Used\")\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        print(f\"  GPU Memory: {torch.cuda.memory_allocated(device)/1024**2:.2f} MB Allocated, {torch.cuda.memory_reserved(device)/1024**2:.2f} MB Reserved\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Wywołaj garbage collector na koniec epoki\n",
    "    gc.collect()\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "# --- (Opcjonalnie) Zapisanie modelu ---\n",
    "# print(\"Saving model...\")\n",
    "# torch.save(model.state_dict(), \"cub200_resnet18_pytorch.pth\")\n",
    "# print(\"Model saved to cub200_resnet18_pytorch.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
