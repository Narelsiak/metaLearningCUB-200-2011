{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-06 11:38:34.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmeta_project.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\Michal\\Desktop\\MAML\\metaLearningCUB-200-2011\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                         image_name  image_id  class_id  \\\n",
      "0   1  001.Black_footed_Albatross/Black_Footed_Albatr...         1         1   \n",
      "1   2  001.Black_footed_Albatross/Black_Footed_Albatr...         2         1   \n",
      "2   3  001.Black_footed_Albatross/Black_Footed_Albatr...         3         1   \n",
      "3   4  001.Black_footed_Albatross/Black_Footed_Albatr...         4         1   \n",
      "4   5  001.Black_footed_Albatross/Black_Footed_Albatr...         5         1   \n",
      "\n",
      "                   class_name  is_training_image  \n",
      "0  001.Black_footed_Albatross                  0  \n",
      "1  001.Black_footed_Albatross                  1  \n",
      "2  001.Black_footed_Albatross                  0  \n",
      "3  001.Black_footed_Albatross                  1  \n",
      "4  001.Black_footed_Albatross                  1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>is_training_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         image_name  image_id  class_id  \\\n",
       "0   1  001.Black_footed_Albatross/Black_Footed_Albatr...         1         1   \n",
       "1   2  001.Black_footed_Albatross/Black_Footed_Albatr...         2         1   \n",
       "2   3  001.Black_footed_Albatross/Black_Footed_Albatr...         3         1   \n",
       "3   4  001.Black_footed_Albatross/Black_Footed_Albatr...         4         1   \n",
       "4   5  001.Black_footed_Albatross/Black_Footed_Albatr...         5         1   \n",
       "\n",
       "                   class_name  is_training_image  \n",
       "0  001.Black_footed_Albatross                  0  \n",
       "1  001.Black_footed_Albatross                  1  \n",
       "2  001.Black_footed_Albatross                  0  \n",
       "3  001.Black_footed_Albatross                  1  \n",
       "4  001.Black_footed_Albatross                  1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from meta_project.data.data_loader import DataLoader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "df = data_loader.load_and_merge_data()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3090 Ti\n",
      "Loading dataset using ImageFolder...\n",
      "Found 11788 images in 200 classes.\n",
      "Splitting into Train (8841) and Test (2947) sets...\n",
      "Dataset split complete.\n",
      "Creating DataLoaders with Batch Size: 8, Num Workers: 4\n",
      "DataLoaders created.\n",
      "Loading ResNet18 model...\n",
      "Modified final layer for 200 classes.\n",
      "Model moved to device.\n",
      "Loss function and optimizer defined.\n",
      "\n",
      "--- Starting Training for 10 Epochs ---\n",
      "Initial RAM Usage: 40.1% Used\n",
      "Initial GPU Memory: 155.43 MB Allocated, 508.00 MB Reserved\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 272, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [3, 256, 341] at entry 0 and [3, 256, 384] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m    121\u001b[39m batches_processed_train = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1465\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1464\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\_utils.py:715\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    712\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mRuntimeError\u001b[39m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Michal\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\meta-project-hyzyb4Sq-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 272, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [3, 256, 341] at entry 0 and [3, 256, 384] at entry 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import copy # To deepcopy datasets if needed, though Subset approach is better\n",
    "\n",
    "# --- Configuration ---\n",
    "ROOT_DIR = os.path.join(os.getcwd(), \"data\", \"raw\", \"CUB_200_2011\", \"images\")\n",
    "EPOCHS = 5 # Reduce epochs for faster hyperparameter search trials\n",
    "TEST_SPLIT_RATIO = 0.25\n",
    "NUM_WORKERS = 4 # Adjust based on your system\n",
    "SEED = 42 # For reproducibility\n",
    "\n",
    "# --- Hyperparameter Search Space ---\n",
    "NUM_TRIALS = 5 # Number of random configurations to try\n",
    "\n",
    "HP_SEARCH_SPACE = {\n",
    "    'lr': [1e-5, 1e-4, 5e-4, 1e-3],\n",
    "    'batch_size': [8, 16, 32], # Be careful with GPU memory for larger batches\n",
    "    'optimizer': ['Adam', 'SGD'],\n",
    "    'sgd_momentum': [0.9] # Only relevant if SGD is chosen\n",
    "}\n",
    "\n",
    "# --- Setup ---\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Might make things slower, but ensures reproducibility for convolutions\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    raise FileNotFoundError(f\"Dataset directory not found: {ROOT_DIR}. \"\n",
    "                         \"Please ensure the CUB_200_2011 dataset is downloaded and extracted correctly.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# --- Dataset Loading and Splitting (Done ONCE) ---\n",
    "print(\"Loading dataset metadata...\")\n",
    "full_dataset_meta = datasets.ImageFolder(root=ROOT_DIR) # Load once to get classes and size\n",
    "class_names = full_dataset_meta.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "if num_classes == 0:\n",
    "    raise ValueError(f\"No classes found in {ROOT_DIR}. Check dataset structure.\")\n",
    "if num_classes != 200:\n",
    "     print(f\"Warning: Expected 200 classes, but found {num_classes}. Check dataset structure.\")\n",
    "\n",
    "total_size = len(full_dataset_meta)\n",
    "test_size = int(TEST_SPLIT_RATIO * total_size)\n",
    "train_size = total_size - test_size\n",
    "print(f\"Total images: {total_size}. Splitting into Train ({train_size}) and Test ({test_size}).\")\n",
    "\n",
    "# Define transforms\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Create datasets with respective transforms *before* subsetting\n",
    "# This is important so subsets refer to correctly transformed data\n",
    "train_dataset_base = datasets.ImageFolder(root=ROOT_DIR, transform=transform_train)\n",
    "test_dataset_base = datasets.ImageFolder(root=ROOT_DIR, transform=transform_test)\n",
    "\n",
    "# Generate split indices\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "indices = list(range(total_size))\n",
    "train_indices, test_indices = random_split(indices, [train_size, test_size], generator=generator)\n",
    "\n",
    "# Create subsets using the *same* indices but different base datasets (with different transforms)\n",
    "train_subset = Subset(train_dataset_base, train_indices)\n",
    "test_subset = Subset(test_dataset_base, test_indices)\n",
    "print(\"Dataset split using Subsets complete.\")\n",
    "\n",
    "del full_dataset_meta, train_dataset_base, test_dataset_base # Free up memory\n",
    "\n",
    "\n",
    "# --- Training and Evaluation Function ---\n",
    "def train_evaluate(config, trial_num):\n",
    "    \"\"\"Trains and evaluates a model for one hyperparameter configuration.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"--- Starting Trial {trial_num+1}/{NUM_TRIALS} ---\")\n",
    "    print(f\"Config: {config}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Extract config\n",
    "    lr = config['lr']\n",
    "    batch_size = config['batch_size']\n",
    "    optimizer_name = config['optimizer']\n",
    "\n",
    "    # Create DataLoaders for this trial (important to use current batch_size)\n",
    "    use_persistent_workers = NUM_WORKERS > 0\n",
    "    try:\n",
    "        train_loader = DataLoader(\n",
    "            train_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=use_persistent_workers,\n",
    "            # Use drop_last=True if batch size doesn't evenly divide dataset size\n",
    "            # drop_last=True\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=use_persistent_workers\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "         if \"DataLoader worker (pid\" in str(e) and use_persistent_workers:\n",
    "             print(\"\\nWARNING: Caught DataLoader worker issue with persistent_workers=True.\")\n",
    "             print(\"Retrying with persistent_workers=False for this trial.\")\n",
    "             print(\"This might happen after previous crashes or forceful interruptions.\\n\")\n",
    "             use_persistent_workers = False # Disable for this trial\n",
    "             train_loader = DataLoader(\n",
    "                 train_subset, batch_size=batch_size, shuffle=True,\n",
    "                 num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=False\n",
    "             )\n",
    "             test_loader = DataLoader(\n",
    "                 test_subset, batch_size=batch_size, shuffle=False,\n",
    "                 num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=False\n",
    "             )\n",
    "         else:\n",
    "            raise e # Reraise other runtime errors\n",
    "\n",
    "    print(f\"DataLoaders created for trial {trial_num+1} (Batch Size: {batch_size}, Persistent Workers: {use_persistent_workers}).\")\n",
    "\n",
    "\n",
    "    # Create Model for this trial (load fresh weights)\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    model.to(device)\n",
    "    print(\"Model created and moved to device.\")\n",
    "\n",
    "    # Create Optimizer for this trial\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=config['sgd_momentum'])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "    print(f\"Optimizer ({optimizer_name}) created.\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"\\n--- Training Trial {trial_num+1} for {EPOCHS} Epochs ---\")\n",
    "    print(f\"Initial RAM Usage: {psutil.virtual_memory().percent}% Used\")\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.reset_peak_memory_stats(device) # Reset peak counter for the trial\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_allocated(device)/1024**2:.2f} MB Allocated, {torch.cuda.memory_reserved(device)/1024**2:.2f} MB Reserved\")\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time_epoch = time.time()\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "        batches_processed_train = 0\n",
    "        epoch_start_mem_alloc = torch.cuda.memory_allocated(device) if device == torch.device(\"cuda\") else 0\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Check if batch is valid (sometimes DataLoader yields None on error)\n",
    "            if batch is None:\n",
    "                print(f\"Warning: DataLoader yielded None for batch {i}. Skipping.\")\n",
    "                continue\n",
    "            inputs, labels = batch\n",
    "            start_time_batch = time.time()\n",
    "            inputs = inputs.to(device, non_blocking=True) # Use non_blocking with pin_memory\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True) # Use set_to_none=True for potential speedup\n",
    "\n",
    "            try:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss_train += loss.item()\n",
    "                batches_processed_train += 1\n",
    "\n",
    "                if (i + 1) % 50 == 0: # Log less frequently during hyperparameter search\n",
    "                    avg_loss_recent = running_loss_train / batches_processed_train if batches_processed_train > 0 else 0\n",
    "                    batch_time = time.time() - start_time_batch\n",
    "                    print(f'  Batch [{i+1:>4}/{len(train_loader):>4}] Train Loss: {loss.item():.4f} (Avg: {avg_loss_recent:.4f}) | Time/Batch: {batch_time:.3f}s')\n",
    "\n",
    "                # Manual cleanup inside batch loop (more aggressive)\n",
    "                del inputs, labels, outputs, loss\n",
    "                # Note: Frequent cache emptying can slow down training but helps prevent OOM\n",
    "                # if device == torch.device(\"cuda\"):\n",
    "                #     torch.cuda.empty_cache()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    print(f\"\\nCUDA out of memory during training batch {i+1}!\")\n",
    "                    print(f\"Batch size: {batch_size}, Model: ResNet18\")\n",
    "                    print(f\"Memory Allocated: {torch.cuda.memory_allocated(device)/1024**2:.2f} MB\")\n",
    "                    print(f\"Memory Reserved: {torch.cuda.memory_reserved(device)/1024**2:.2f} MB\")\n",
    "                    # Option 1: Skip the rest of the epoch/trial (might be cleaner)\n",
    "                    # return {'error': 'OOM', 'config': config}\n",
    "                    # Option 2: Try to recover (might be unstable)\n",
    "                    print(\"Attempting to clear cache and skip batch...\")\n",
    "                    gc.collect()\n",
    "                    if device == torch.device(\"cuda\"): torch.cuda.empty_cache()\n",
    "                    continue # Skip to next batch\n",
    "                else:\n",
    "                    raise e # Re-raise other runtime errors\n",
    "\n",
    "        epoch_loss_train = running_loss_train / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        history['train_loss'].append(epoch_loss_train)\n",
    "        epoch_end_mem_alloc = torch.cuda.memory_allocated(device) if device == torch.device(\"cuda\") else 0\n",
    "        print(f\"Epoch {epoch+1} Training Phase Complete. Avg Train Loss: {epoch_loss_train:.4f}\")\n",
    "        if device == torch.device(\"cuda\"):\n",
    "             print(f\"  GPU Mem Change (Train): {(epoch_end_mem_alloc - epoch_start_mem_alloc)/1024**2:+.2f} MB\")\n",
    "\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        running_loss_val = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        epoch_start_mem_alloc_val = torch.cuda.memory_allocated(device) if device == torch.device(\"cuda\") else 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(test_loader):\n",
    "                 if batch is None:\n",
    "                     print(f\"Warning: DataLoader yielded None for validation batch {i}. Skipping.\")\n",
    "                     continue\n",
    "                 inputs, labels = batch\n",
    "                 inputs = inputs.to(device, non_blocking=True)\n",
    "                 labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                 try:\n",
    "                     outputs = model(inputs)\n",
    "                     loss = criterion(outputs, labels)\n",
    "                     running_loss_val += loss.item()\n",
    "\n",
    "                     _, predicted = torch.max(outputs.data, 1)\n",
    "                     total_val += labels.size(0)\n",
    "                     correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "                     del inputs, labels, outputs, loss, predicted # Manual cleanup\n",
    "\n",
    "                 except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        print(f\"\\nCUDA out of memory during validation batch {i+1}!\")\n",
    "                        # Less critical than train OOM, but still problematic\n",
    "                        print(\"Attempting to clear cache and skip batch...\")\n",
    "                        gc.collect()\n",
    "                        if device == torch.device(\"cuda\"): torch.cuda.empty_cache()\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "\n",
    "        epoch_loss_val = running_loss_val / len(test_loader) if len(test_loader) > 0 else 0\n",
    "        epoch_acc_val = 100 * correct_val / total_val if total_val > 0 else 0\n",
    "        history['val_loss'].append(epoch_loss_val)\n",
    "        history['val_acc'].append(epoch_acc_val)\n",
    "\n",
    "        if epoch_acc_val > best_val_acc:\n",
    "            best_val_acc = epoch_acc_val\n",
    "\n",
    "        end_time_epoch = time.time()\n",
    "        epoch_duration = end_time_epoch - start_time_epoch\n",
    "        epoch_end_mem_alloc_val = torch.cuda.memory_allocated(device) if device == torch.device(\"cuda\") else 0\n",
    "\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Epoch {epoch+1} Summary:\")\n",
    "        print(f\"  Train Loss: {epoch_loss_train:.4f}\")\n",
    "        print(f\"  Val Loss:   {epoch_loss_val:.4f}\")\n",
    "        print(f\"  Val Acc:    {epoch_acc_val:.2f}% (Best: {best_val_acc:.2f}%)\")\n",
    "        print(f\"  Duration:   {epoch_duration:.2f}s\")\n",
    "        print(f\"  RAM Usage: {psutil.virtual_memory().percent}% Used\")\n",
    "        if device == torch.device(\"cuda\"):\n",
    "            current_mem_alloc = torch.cuda.memory_allocated(device)\n",
    "            current_mem_reserv = torch.cuda.memory_reserved(device)\n",
    "            peak_mem_alloc = torch.cuda.max_memory_allocated(device) # Peak for the entire trial so far\n",
    "            print(f\"  GPU Mem Change (Val): {(epoch_end_mem_alloc_val - epoch_start_mem_alloc_val)/1024**2:+.2f} MB\")\n",
    "            print(f\"  GPU Mem Current: {current_mem_alloc/1024**2:.2f} MB Allocated, {current_mem_reserv/1024**2:.2f} MB Reserved\")\n",
    "            print(f\"  GPU Mem Peak (Trial): {peak_mem_alloc/1024**2:.2f} MB Allocated\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # # Optional: More aggressive cleanup between epochs\n",
    "        # gc.collect()\n",
    "        # if device == torch.device(\"cuda\"):\n",
    "        #     torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n--- Finished Trial {trial_num+1} ---\")\n",
    "    print(f\"Best Validation Accuracy for this trial: {best_val_acc:.2f}%\")\n",
    "\n",
    "    # Clean up explicitly before next trial\n",
    "    del model, optimizer, criterion, train_loader, test_loader\n",
    "    gc.collect()\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"GPU Memory after trial cleanup: {torch.cuda.memory_allocated(device)/1024**2:.2f} MB Allocated, {torch.cuda.memory_reserved(device)/1024**2:.2f} MB Reserved\")\n",
    "\n",
    "\n",
    "    return {'config': config, 'best_val_acc': best_val_acc, 'history': history}\n",
    "\n",
    "\n",
    "# --- Main Hyperparameter Search Loop ---\n",
    "results = []\n",
    "\n",
    "for trial_idx in range(NUM_TRIALS):\n",
    "    # Sample random hyperparameters\n",
    "    config = {\n",
    "        'lr': random.choice(HP_SEARCH_SPACE['lr']),\n",
    "        'batch_size': random.choice(HP_SEARCH_SPACE['batch_size']),\n",
    "        'optimizer': random.choice(HP_SEARCH_SPACE['optimizer']),\n",
    "    }\n",
    "    if config['optimizer'] == 'SGD':\n",
    "        config['sgd_momentum'] = random.choice(HP_SEARCH_SPACE['sgd_momentum'])\n",
    "    else:\n",
    "        # Assign a default/placeholder if momentum isn't used by the optimizer\n",
    "        config['sgd_momentum'] = None # Or np.nan or similar\n",
    "\n",
    "\n",
    "    # Run training and evaluation for the sampled config\n",
    "    try:\n",
    "         trial_result = train_evaluate(config, trial_idx)\n",
    "         if trial_result and 'error' not in trial_result:\n",
    "             results.append(trial_result)\n",
    "         elif trial_result and 'error' in trial_result:\n",
    "             print(f\"Trial {trial_idx+1} failed with error: {trial_result['error']}\")\n",
    "             # Optionally store failed trials too:\n",
    "             # results.append(trial_result)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n!!!!!!!! CRITICAL ERROR IN TRIAL {trial_idx+1} !!!!!!!!\")\n",
    "        print(f\"Config: {config}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        # Clean up GPU memory if possible after a crash\n",
    "        del config # remove reference\n",
    "        gc.collect()\n",
    "        if device == torch.device(\"cuda\"):\n",
    "             torch.cuda.empty_cache()\n",
    "        # Continue to the next trial\n",
    "        continue\n",
    "\n",
    "\n",
    "# --- Post-Search Analysis ---\n",
    "print(\"\\n\\n\" + \"*\"*70)\n",
    "print(\"--- Hyperparameter Search Finished ---\")\n",
    "print(f\"Ran {len(results)} successful trials.\")\n",
    "\n",
    "if not results:\n",
    "    print(\"No trials completed successfully.\")\n",
    "else:\n",
    "    # Sort results by best validation accuracy (descending)\n",
    "    results.sort(key=lambda x: x.get('best_val_acc', -1), reverse=True) # Use .get for safety if a trial failed before producing acc\n",
    "\n",
    "    print(\"\\nTop 5 Configurations (by Best Validation Accuracy):\")\n",
    "    for i, result in enumerate(results[:5]):\n",
    "        print(f\"  Rank {i+1}:\")\n",
    "        print(f\"    Config: {result['config']}\")\n",
    "        print(f\"    Best Val Acc: {result.get('best_val_acc', 'N/A'):.2f}%\") # Use .get again\n",
    "        # Optionally print final epoch metrics\n",
    "        if 'history' in result and result['history']['val_acc']:\n",
    "             print(f\"    Final Val Acc: {result['history']['val_acc'][-1]:.2f}%\")\n",
    "             print(f\"    Final Train Loss: {result['history']['train_loss'][-1]:.4f}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    best_config = results[0]['config']\n",
    "    best_accuracy = results[0]['best_val_acc']\n",
    "    print(f\"\\nBest Overall Configuration Found:\")\n",
    "    print(f\"  Config: {best_config}\")\n",
    "    print(f\"  Best Validation Accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "print(\"*\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
